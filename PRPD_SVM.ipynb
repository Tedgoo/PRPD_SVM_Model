{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efb89c8",
   "metadata": {},
   "source": [
    "# 220115 SVM Classfication model\n",
    "### - GIS Partial Discharge Signal: Noise , Surface PD, Particle PD\n",
    "### - Sensor: PD SENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a368c",
   "metadata": {},
   "source": [
    "## 1. Python Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49291df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정 패키지\n",
    "import os\n",
    "\n",
    "# 데이터 전처리 패키지\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler #정규화 패키지\n",
    "\n",
    "# 기계학습 모델 및 평가 패키지\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시각화 패키지\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#한글 폰트 설정 \n",
    "plt.rc('font', family='Malgun Gothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fb71f",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d39066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taeyu\\PRPD data Test\\data\\noise\n"
     ]
    }
   ],
   "source": [
    "# Noise_data\n",
    "\n",
    "os.chdir(\"C:/Users/taeyu/PRPD data Test/data/noise\") #데이터 경로\n",
    "print(os.getcwd())\n",
    "\n",
    "data_name = []\n",
    "\n",
    "for i in range(30):\n",
    "    data = 'noise ({0}).csv'.format(i)\n",
    "    data_name.append(data)\n",
    "\n",
    "    \n",
    "    \n",
    "for j, k in zip(range(0,50),data_name):    \n",
    "    df = pd.read_csv(k, header=None, index_col = False) # Dataframe 데이터\n",
    "    test_data= df.to_numpy() # ndarray data\n",
    "    \n",
    "    feature_file = np.ones((3600,10), dtype=None, order='C')\n",
    "    feature_file_mean = np.ones((1,11), dtype=None, order='C')\n",
    "    \n",
    "    for a in (range(3600)):\n",
    "        feature_file[a,0] = skew(test_data[a,0:63]); # 60hZ 반주기 왜도(Positive)\n",
    "        feature_file[a,1] = skew(test_data[a,64:127]); # 60hZ 반주기 왜도(Negaitive)\n",
    "        feature_file[a,2] = kurtosis(test_data[a,0:63]); # 60hZ 반주기 첨도(Positive)\n",
    "        feature_file[a,3] = kurtosis(test_data[a,64:127]); # 60hZ 반주기 첨도(Negaitive)\n",
    "        feature_file[a,4] = np.max(test_data[a,0:63]); # 60hZ 반주기 최대값(Positive)\n",
    "        feature_file[a,5] = np.max(test_data[a,64:127]); # 60hZ 반주기 최대값(Negaitive)\n",
    "        feature_file[a,6] = np.mean(test_data[a,0:63]); # 60hZ 반주기 평균(Positive)\n",
    "        feature_file[a,7] = np.mean(test_data[a,64:127]); # 60hZ 반주기 평균(Negaitive)\n",
    "        feature_file[a,8] = np.count_nonzero(test_data[a,0:63]>40); # 60hZ 반주기 PD 신호 개수, threshhold 수정 \n",
    "        feature_file[a,9] = np.count_nonzero(test_data[a,64:127]>40); # 60hZ 반주기 PD 신호 개수, threshhold 수정 \n",
    "        \n",
    "        feature_file_mean[0,0] = np.mean(feature_file[:,0]); #3600 사이클 평균 \n",
    "        feature_file_mean[0,1] = np.mean(feature_file[:,1]); \n",
    "        feature_file_mean[0,2] = np.mean(feature_file[:,2]);\n",
    "        feature_file_mean[0,3] = np.mean(feature_file[:,3]);\n",
    "        feature_file_mean[0,4] = np.mean(feature_file[:,4]);\n",
    "        feature_file_mean[0,5] = np.mean(feature_file[:,5]);\n",
    "        feature_file_mean[0,6] = np.mean(feature_file[:,6]);\n",
    "        feature_file_mean[0,7] = np.mean(feature_file[:,7]);\n",
    "        feature_file_mean[0,8] = np.mean(feature_file[:,8]);\n",
    "        feature_file_mean[0,9] = np.mean(feature_file[:,9]);\n",
    "        feature_file_mean[0,10] = 0 # Noise 라벨링 \n",
    "        \n",
    "    globals()['prpd_{}'.format(j)] = pd.DataFrame(feature_file_mean);\n",
    "\n",
    "\n",
    "df_noise = pd.concat([prpd_0, prpd_1, prpd_2, prpd_3, prpd_4, prpd_5, prpd_6, prpd_7, prpd_8, prpd_9, prpd_10, prpd_11,\n",
    "                         prpd_12, prpd_13,  prpd_14, prpd_15 , prpd_16,  prpd_17, prpd_18, prpd_19, prpd_20,\n",
    "                         prpd_21 , prpd_22,prpd_23,  prpd_24 , prpd_25, prpd_26,  prpd_27,  prpd_28, prpd_29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21287919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taeyu\\PRPD data Test\\data\\surface\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prpd_30' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_10168/2677266958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m df_surface = pd.concat([prpd_0, prpd_1, prpd_2, prpd_3, prpd_4, prpd_5, prpd_6, prpd_7, prpd_8, prpd_9, prpd_10, prpd_11,\n\u001b[0;32m     49\u001b[0m                          \u001b[0mprpd_12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprpd_13\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mprpd_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprpd_15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mprpd_16\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mprpd_17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprpd_18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprpd_19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprpd_20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                          prpd_21 , prpd_22,prpd_23,  prpd_24 , prpd_25, prpd_26,  prpd_27,  prpd_28, prpd_29,  prpd_30]) #수정 \n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prpd_30' is not defined"
     ]
    }
   ],
   "source": [
    "# Surface_data\n",
    "\n",
    "os.chdir(\"C:/Users/taeyu/PRPD data Test/data/surface\") \n",
    "print(os.getcwd())\n",
    "\n",
    "data_name = []\n",
    "\n",
    "for i in range(30):\n",
    "    data = 'surface ({0}).csv'.format(i)\n",
    "    data_name.append(data)\n",
    "\n",
    "    \n",
    "    \n",
    "for j, k in zip(range(0,50),data_name):    \n",
    "    df = pd.read_csv(k, header=None, index_col = False) # Dataframe 데이터\n",
    "    test_data= df.to_numpy() # ndarray data\n",
    "    \n",
    "    feature_file = np.ones((3600,10), dtype=None, order='C')\n",
    "    feature_file_mean = np.ones((1,11), dtype=None, order='C')\n",
    "    \n",
    "    for a in (range(3600)):\n",
    "        feature_file[a,0] = skew(test_data[a,0:63]);\n",
    "        feature_file[a,1] = skew(test_data[a,64:127]);\n",
    "        feature_file[a,2] = kurtosis(test_data[a,0:63]);\n",
    "        feature_file[a,3] = kurtosis(test_data[a,64:127]);\n",
    "        feature_file[a,4] = np.max(test_data[a,0:63]);\n",
    "        feature_file[a,5] = np.max(test_data[a,64:127]);\n",
    "        feature_file[a,6] = np.mean(test_data[a,0:63]);\n",
    "        feature_file[a,7] = np.mean(test_data[a,64:127]);\n",
    "        feature_file[a,8] = np.count_nonzero(test_data[a,0:63]>40); #  threshhold 수정\n",
    "        feature_file[a,9] = np.count_nonzero(test_data[a,64:127]>40); #  threshhold 수정\n",
    "        \n",
    "        feature_file_mean[0,0] = np.mean(feature_file[:,0]);\n",
    "        feature_file_mean[0,1] = np.mean(feature_file[:,1]);\n",
    "        feature_file_mean[0,2] = np.mean(feature_file[:,2]);\n",
    "        feature_file_mean[0,3] = np.mean(feature_file[:,3]);\n",
    "        feature_file_mean[0,4] = np.mean(feature_file[:,4]);\n",
    "        feature_file_mean[0,5] = np.mean(feature_file[:,5]);\n",
    "        feature_file_mean[0,6] = np.mean(feature_file[:,6]);\n",
    "        feature_file_mean[0,7] = np.mean(feature_file[:,7]);\n",
    "        feature_file_mean[0,8] = np.mean(feature_file[:,8]);\n",
    "        feature_file_mean[0,9] = np.mean(feature_file[:,9]);\n",
    "        feature_file_mean[0,10] = 1 # Surface 라벨링              \n",
    "        \n",
    "    globals()['prpd_{}'.format(j)] = pd.DataFrame(feature_file_mean);\n",
    "\n",
    "\n",
    "df_surface = pd.concat([prpd_0, prpd_1, prpd_2, prpd_3, prpd_4, prpd_5, prpd_6, prpd_7, prpd_8, prpd_9, prpd_10, prpd_11,\n",
    "                         prpd_12, prpd_13,  prpd_14, prpd_15 , prpd_16,  prpd_17, prpd_18, prpd_19, prpd_20,\n",
    "                         prpd_21 , prpd_22,prpd_23,  prpd_24 , prpd_25, prpd_26,  prpd_27,  prpd_28, prpd_29,  prpd_30]) #수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle_data\n",
    "\n",
    "os.chdir(\"C:/Users/taeyu/PRPD data Test/data/particle\") #수정 \n",
    "print(os.getcwd())\n",
    "\n",
    "data_name = []\n",
    "\n",
    "for i in range(30):\n",
    "    data = 'particle ({0}).csv'.format(i) #수정 \n",
    "    data_name.append(data)\n",
    "\n",
    "    \n",
    "    \n",
    "for j, k in zip(range(0,50),data_name):    \n",
    "    df = pd.read_csv(k, header=None, index_col = False) # Dataframe 데이터\n",
    "    test_data= df.to_numpy() # ndarray data\n",
    "    \n",
    "    feature_file = np.ones((3600,10), dtype=None, order='C')\n",
    "    feature_file_mean = np.ones((1,11), dtype=None, order='C')\n",
    "    \n",
    "    for a in (range(3600)):\n",
    "        feature_file[a,0] = skew(test_data[a,0:63]);\n",
    "        feature_file[a,1] = skew(test_data[a,64:127]);\n",
    "        feature_file[a,2] = kurtosis(test_data[a,0:63]);\n",
    "        feature_file[a,3] = kurtosis(test_data[a,64:127]);\n",
    "        feature_file[a,4] = np.max(test_data[a,0:63]);\n",
    "        feature_file[a,5] = np.max(test_data[a,64:127]);\n",
    "        feature_file[a,6] = np.mean(test_data[a,0:63]);\n",
    "        feature_file[a,7] = np.mean(test_data[a,64:127]);\n",
    "        feature_file[a,8] = np.count_nonzero(test_data[a,0:63]>40); #  threshhold 수정\n",
    "        feature_file[a,9] = np.count_nonzero(test_data[a,64:127]>40); #  threshhold 수정\n",
    "        \n",
    "        feature_file_mean[0,0] = np.mean(feature_file[:,0]);\n",
    "        feature_file_mean[0,1] = np.mean(feature_file[:,1]);\n",
    "        feature_file_mean[0,2] = np.mean(feature_file[:,2]);\n",
    "        feature_file_mean[0,3] = np.mean(feature_file[:,3]);\n",
    "        feature_file_mean[0,4] = np.mean(feature_file[:,4]);\n",
    "        feature_file_mean[0,5] = np.mean(feature_file[:,5]);\n",
    "        feature_file_mean[0,6] = np.mean(feature_file[:,6]);\n",
    "        feature_file_mean[0,7] = np.mean(feature_file[:,7]);\n",
    "        feature_file_mean[0,8] = np.mean(feature_file[:,8]);\n",
    "        feature_file_mean[0,9] = np.mean(feature_file[:,9]);\n",
    "        feature_file_mean[0,10] = 2 # Particle 라벨링        수정필요\n",
    "        \n",
    "    globals()['prpd_{}'.format(j)] = pd.DataFrame(feature_file_mean);\n",
    "\n",
    "\n",
    "df_particle = pd.concat([prpd_0, prpd_1, prpd_2, prpd_3, prpd_4, prpd_5, prpd_6, prpd_7, prpd_8, prpd_9, prpd_10, prpd_11,\n",
    "                         prpd_12, prpd_13,  prpd_14, prpd_15 , prpd_16,  prpd_17, prpd_18, prpd_19, prpd_20,\n",
    "                         prpd_21 , prpd_22,prpd_23,  prpd_24 , prpd_25, prpd_26,  prpd_27,  prpd_28, prpd_29,  prpd_30]) #수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783cc5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_particle.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68584392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surface.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9019cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([df_noise, df_surface, df_particle])\n",
    "\n",
    "os.chdir(\"C:/Users/taeyu/PRPD data Test\") #수정 \n",
    "print(os.getcwd())\n",
    "\n",
    "final_data.to_csv('prpd_final.csv', index=False, header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc407e14",
   "metadata": {},
   "source": [
    "## 3. 데이터 불러오기(다변랑 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prpd_final.csv', header=None, index_col = False) # Dataframe 데이터\n",
    "df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05aca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # 통계량값 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95db648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy() # ndarray data\n",
    "print(data)  # 데이터 인덱싱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:10] # 독립 변수(feature)\n",
    "Y = data[:,10] # 종속 변수 (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e960aff",
   "metadata": {},
   "source": [
    "## 4. 데이터 분리(학습 8: 테스트 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82824d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2022) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726edb44",
   "metadata": {},
   "source": [
    "## 5. 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05716df",
   "metadata": {},
   "source": [
    "## 6. SVM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 학습 (Best 조건)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel='rbf', gamma=0.01, C=1)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "classifier.score(X_test,Y_test)\n",
    "\n",
    "## DecisionTreeClassifier() 트리모델\n",
    "## RandomForestClassifier() 랜덤포레스트\n",
    "## KNeighborsClassifier() K-최접근 \n",
    "## SVC(kernel=\"linear\"), 서포터 벡터 머신 \n",
    "## GaussianNB(), 가우시안 NB\n",
    "## LogisticRegression(), 로지스트 회귀 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0c1a0",
   "metadata": {},
   "source": [
    "## 7. 학습결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238282f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test acc\n",
    "\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(Y_train, Y_train_pred)\n",
    "acc_test = accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "print('Training Accuracy: {:3f}'. format(acc_train))\n",
    "print('Testing Accuracy: {:3f}'. format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼돈 행렬 (대각선 이외의 값은 예측에 실패한 개수를 표현하기 때문에 대각선 값이 크게 나타나야지 좋다고 볼수 있음, 테스트에 90개 사용)\n",
    "plot_confusion_matrix(classifier, X_test, Y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580982a",
   "metadata": {},
   "source": [
    "## 8. 최적화 및 교차 검증(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "  \n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose= 3)\n",
    "\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, Y_train);\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5257a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1bf38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
